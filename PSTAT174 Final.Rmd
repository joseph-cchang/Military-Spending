---
title: "PSTAT174 Project"
author: "Joseph Chang"
date: "3/11/2022"
output: pdf_document
---

```{r setup, include=FALSE}
#install.packages(c('tidyverse', 'knitr'))
knitr::opts_chunk$set(echo = TRUE)
library(knitr)
library(tidyverse) 
library(ISLR) 
library(ROCR)
library(dplyr)
library(tinytex)
library(MASS)
devtools::install_github("FinYang/tsdl")
library(tsdl)
library(forecast)
library(astsa)
library(qpcR)
```

# Project description 
The data set I plan to use is the US military expense since 1960. This is money that the US military has used for the defense budget. Although the dataset has two other columns with population of U.S. and GDP, I think the defense budget is more interesting. The GDP and population follow a constant, linear relationship.

# Project motivations and objectives
This data is interesting to me because I have been studying history, especially US history and the wars it has fought or participated in. This data gives me an idea how much the US government spent during the wars and also in the present day. I plan to address the prediction of the defense budget in the next few years (forecasting).

There seems to be a trend that is positive but there is no seasonality and no apparent sharp change in behavior.

## Data Import
```{r}
# reading in dataset
spending_data <- read.csv("/Users/josephchang/Desktop/MilitarySpending.csv.xls")

plot.ts(spending_data$Year, spending_data$DefenseBudget, ylab = "Defense budget (in US billion)", xlab = "Year", type="l")

plot(spending_data$Year, spending_data$DefenseBudget, ylab = "Defense budget (in US billion)", xlab = "Year", type="l")
```

# transformation
```{r}
# boxcox transformation
t = 1:length(spending_data$DefenseBudget)
fit = lm(spending_data$DefenseBudget~t)
bcTransform = boxcox(spending_data$DefenseBudget ~ t, plotit=TRUE)

# best lambda
lambda = bcTransform$x[which(bcTransform$y == max(bcTransform$y))]
spent = (1/lambda)*(spending_data$DefenseBudget^lambda-1)

spending_data.log = log(spending_data$DefenseBudget)
plot.ts(spending_data.log)

spending_data.sqrt = log(spending_data$DefenseBudget)
plot.ts(spending_data.sqrt)

# compare transforms
op=par(mfrow=c(2,2))
ts.plot(spending_data$DefenseBudget, main = "Original Time Series")
ts.plot(spent, main = "Box-cox Transform")
ts.plot(spending_data.log, main = "Log transform")
ts.plot(spending_data.sqrt, main = "Square root transform")

# histogram of spent vs original
hist(spent)
hist(spending_data$DefenseBudget)
# spent seems more normal while original is skewed

# time series plot of spent vs original
plot.ts(spent)
plot.ts(spending_data$DefenseBudget)
# both plots look around the same, but spent seems to have more spent in the median


# Based from the histogram, I will use the spent instead of the original data 
```

## Differencing
```{r}
# difference once
dat <- diff(spent, 1)
dat
plot.ts(dat, type= "l")

# twice differenced
dat.2 <- diff(dat, 1)
dat.2
plot.ts(dat.2, type= "l")

# three times differenced
dat.3 <- diff(dat.2,1)
dat.3
plot(dat.3, type= "l")

# check variance
var(spent)
var(dat)
var(dat.2)
var(dat.3)

# I differenced the data and found d to be 2. Based from the variance, the lowest variance is when d=2. At d=3, variance is increased again, therefore I will take d=2.
```


## Model Identification
```{r}
# ACF, PACF for spent
opar <- par(no.readonly = T)
par(mfrow=c(2,1))
acf(spent, lag.max=100)
pacf(spent, lag.max=100)
par(opar)

# ACF, PACF for dat (difference once)
opar <- par(no.readonly = T)
par(mfrow=c(2,1))
acf(dat, lag.max = 100, main="Sample acf", ylim=c(-1,1),xlab="h", ylab= expression(hat(rho)[X](h)))
pacf(dat, lag.max=100, main="Sample pacf", ylim=c(-1,1),xlab="h", ylab= expression(hat(rho)[X](h)))

# ACF, PACF for dat.2 (difference twice)
opar <- par(no.readonly = T)
par(mfrow=c(2,1))
acf(dat.2, lag.max=100, main="Sample acf", ylim=c(-1,1),xlab="h", ylab= expression(hat(rho)[X](h)))
pacf(dat.2, lag.max=100, main="Sample pacf", ylim=c(-1,1),xlab="h", ylab= expression(hat(rho)[X](h)))

```

## Model estimation
```{r}
# Candidate models:
df <- expand.grid(p=0:10, q=0:10) 
df <- cbind(df, AICc=NA)

# Initially, I found lowest AICc using parameters(9,1). However, the coefficient at MA(1) produced a -1.000 value meaning I may have overdifferenced. Therefore, I will revert back to differencing at d=1.

# Compute AICc:
for (i in 1:nrow(df)) {
  sarima.obj <- NULL
  try(arima.obj <- arima(spent, order=c(df$p[i],1, df$q[i]),
method="ML"))
  if (!is.null(arima.obj)) { df$AICc[i] <- AICc(arima.obj) }
  # print(df[i, ])
}
df[which.min(df$AICc), ]

order(df$AICc)
df[order(df$AICc),]
# using principle of parsimony, I will consider (1,0)

# Final model
fit <- arima(spent, order = c(1,1,0), 
             method = "ML")
fit

# model estimation for AR model using Yule-Walker
fit_ar <- ar(dat, method = "yw")

# construct 95% CI
ar1.se <- sqrt(fit_ar$asy.var.coef)
c(fit_ar$ar - 1.96*ar1.se, fit.ar$ar + 1.96*ar1.se)

```

## Model Diagnostics
```{r}
res <- residuals(fit)
mean(res)
var(res)

par(mfrow=c(1,1))
ts.plot(res, main  = "Fitted Residuals")
t <- 1:length(res)
fit.res = lm(res~t)
abline(fit.res)
abline(h=mean(res), col = "blue")

par(mfrow=c(1,2))
acf(res, main = "Autocorrelation")
pacf(res, main = "Partial Autocorrelation")

# Testing for independence of residuals
Box.test(res, lag = 8, type = c("Box-Pierce"), fitdf = 1)

Box.test(res, lag = 8, type = c("Ljung-Box"), fitdf = 1)

Box.test(res^2, lag = 8, type = c("Ljung-Box"), fitdf = 0)

# test for normality of residuals
shapiro.test(res)

# Histogram and qq plot
par(mfrow=c(1,2))
hist(res, main= "Histogram")
qqnorm(res)
qqline(res, col = "blue")
```

Final model should be 
(1-0.97947B)(1-B.....)

## Data Forecasting

```{r}
# Predict 10 future observations and plot
par(mfrow=c(1,1))
mypred <- predict(fit, n.ahead=10)
ts.plot(c(spent), xlim=c(1, length(spent)+10), ylim  = c(min(spent)*0.8, max(spent)*1.2))
points((length(spent)+1):(length(spent) +10), col="red", 
  (lambda*mypred$pred +1)^(1/lambda))
lines((length(spent) +1):(length(spent)+10), 
      (lambda*mypred$pred + 1.96*mypred$se+1)^(1/lambda), lty=2)
lines((length(spent) +1):(length(spent)+10), 
      (lambda*mypred$pred - 1.96*mypred$se+1)^(1/lambda), lty=2)
```


fit model, (for loop) using aICC, find 2 best models, do diagnostics ( boxtest,), bestmodel passes, forecasting
```{r}

```


## Glossary
```{r, eval=FALSE}
# defines working directory
getwd()
setwd("/Users/josephchang/Desktop")

# reads data and plots data
read.csv("/Users/josephchang/Desktop/MilitarySpending.csv.xls")
plot.ts(spend$Year, spend$DefenseBudget)

# simulate and plot ARMA models
plot.ts(arima.sim(model=list(ar=c(0.8), ma=c(0.3)), n = 100, sd = 1), main="ARMA(1,1), ar
c=0.8, ma c=0.3")

plot(0:100,ARMAacf(ar=c(0.8), ma=c(0.3), lag.max=100),xlim=c(1,40),ylab="r",type="h",
main="ACF for ARMA(1,1) ar c=0.8, ma c=0.3") ; abline(h=0)
    
# add trend and mean line to the original time series plot
#abline()
#abline(h=mean(), col='pink')

# calculate and plot theoretical acf/pacf for ARMA models
plot(ARMAacf(ar=c(-0.95), lag.max=40), col = 'blue', type='h', xlab='lag', ylim=c(-0.8,1))
abline(h=0)
plot(ARMAacf(ar=c(-0.95), lag.max=40, pacf=TRUE), type='h', xlab='lag', ylim=c(-0.8,1))
abline(h=0)

# calculate and plot sample acf/pacf;
ar2 <- arima.sim(model=list(ar=c(0.8, -0.12), sd=1), n=200)
acf(ar2, lag.max=20, main="Sample acf", ylim=c(-1,1),xlab="h", ylab= expression(hat(rho)[X](h)))
pacf(ar2, lag.max=20, main="Sample pacf", ylim=c(-1,1),xlab="h", ylab= expression(hat(rho)[X](h)))

# check whether a particular model is causal/invertible (R commands to find and plot roots of polynomials)
polyroot(c(1, -1.3, 0.7))
#source("plot.roots.R")
#plot.roots(NULL,polyroot(c(1, -1.35, 0.77)), main="roots of ar part")
#plot.roots(NULL,polyroot(c(1,0.64)), main="roots of ma part")
#plot.roots(NULL,polyroot(c(1, -2, 2.02, -1.07, 0.34)), main="roots of ar part") 

install.packages("UnitCircle")
library(UnitCircle)
uc.check(pol_ = c(1, -1.35,0.77), plot_output = TRUE)

# perform Box-Cox transforms;
library(MASS)
#t = 1:length(wine)
#fit = lm(wine~t)
#bcTransform = boxcox(wine ~ t, plotit=TRUE)

# perform differencing data at lags 1 and 12;
#uspopdiff1 <- diff(uspop)
#plot.ts(uspopdiff1)
#abline(lm(uspopdiff1 ~ as.numeric(1:length(uspopdiff1))
          
#AP=read.table("pass.txt")
#plot.ts(AP)
#APdiff12 <- diff(AP, lag=12, differences = 1)
#plot.ts(APdiff12)
#abline(lm(APdiff12 ~ as.numeric(1:length(APdiff12))) )
          
# perform Yule-Walker estimation and find standard deviations of the estimates.
#ar(x, aic=TRUE, order.max=NULL, method=c('yule-walker'))
#x.ywest$ar

# perform MLE and check AICC associated with the model.
#x_fit40 = arima(x, order = c(4,0,0), method = "ML")
#library(qpcR)
#AICc(x_fit40)

      # code for a loop to choose a model with lowest AICc:
#for (i in 0:4){for (j in 0:4){ print(i); print(j); print(AICc(arima(x, order = 
#c(i,0,j), method = "ML")))}}
```

