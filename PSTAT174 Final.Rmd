---
title: "PSTAT174 Project"
author: "Joseph Chang"
date: "3/11/2022"
output: pdf_document
---

```{r setup, include=FALSE}
#install.packages(c('tidyverse', 'knitr'))
knitr::opts_chunk$set(echo = TRUE)
library(knitr)
library(tidyverse) 
library(ISLR) 
library(ROCR)
library(dplyr)
library(tinytex)
library(MASS)
#install.packages("devtools")
#install.packages("forecast")
devtools::install_github("FinYang/tsdl")
library(tsdl)
library(forecast)
```

## Glossary
```{r, eval=FALSE}
# defines working directory
getwd()
setwd("/Users/josephchang/Desktop")

# reads data and plots data
read.csv("/Users/josephchang/Desktop/MilitarySpending.csv.xls")
plot.ts(spend$Year, spend$DefenseBudget)

# simulate and plot ARMA models
plot.ts(arima.sim(model=list(ar=c(0.8), ma=c(0.3)), n = 100, sd = 1), main="ARMA(1,1), ar
c=0.8, ma c=0.3")

plot(0:100,ARMAacf(ar=c(0.8), ma=c(0.3), lag.max=100),xlim=c(1,40),ylab="r",type="h",
main="ACF for ARMA(1,1) ar c=0.8, ma c=0.3") ; abline(h=0)
    
# add trend and mean line to the original time series plot
#abline()
#abline(h=mean(), col='pink')

# calculate and plot theoretical acf/pacf for ARMA models
plot(ARMAacf(ar=c(-0.95), lag.max=40), col = 'blue', type='h', xlab='lag', ylim=c(-0.8,1))
abline(h=0)
plot(ARMAacf(ar=c(-0.95), lag.max=40, pacf=TRUE), type='h', xlab='lag', ylim=c(-0.8,1))
abline(h=0)

# calculate and plot sample acf/pacf;
ar2 <- arima.sim(model=list(ar=c(0.8, -0.12), sd=1), n=200)
acf(ar2, lag.max=20, main="Sample acf", ylim=c(-1,1),xlab="h", ylab= expression(hat(rho)[X](h)))
pacf(ar2, lag.max=20, main="Sample pacf", ylim=c(-1,1),xlab="h", ylab= expression(hat(rho)[X](h)))

# check whether a particular model is causal/invertible (R commands to find and plot roots of polynomials)
polyroot(c(1, -1.3, 0.7))
#source("plot.roots.R")
#plot.roots(NULL,polyroot(c(1, -1.35, 0.77)), main="roots of ar part")
#plot.roots(NULL,polyroot(c(1,0.64)), main="roots of ma part")
#plot.roots(NULL,polyroot(c(1, -2, 2.02, -1.07, 0.34)), main="roots of ar part") 

install.packages("UnitCircle")
library(UnitCircle)
uc.check(pol_ = c(1, -1.35,0.77), plot_output = TRUE)

# perform Box-Cox transforms;
library(MASS)
#t = 1:length(wine)
#fit = lm(wine~t)
#bcTransform = boxcox(wine ~ t, plotit=TRUE)

# perform differencing data at lags 1 and 12;
#uspopdiff1 <- diff(uspop)
#plot.ts(uspopdiff1)
#abline(lm(uspopdiff1 ~ as.numeric(1:length(uspopdiff1))
          
#AP=read.table("pass.txt")
#plot.ts(AP)
#APdiff12 <- diff(AP, lag=12, differences = 1)
#plot.ts(APdiff12)
#abline(lm(APdiff12 ~ as.numeric(1:length(APdiff12))) )
          
# perform Yule-Walker estimation and find standard deviations of the estimates.
#ar(x, aic=TRUE, order.max=NULL, method=c('yule-walker'))
#x.ywest$ar

# perform MLE and check AICC associated with the model.
#x_fit40 = arima(x, order = c(4,0,0), method = "ML")
#library(qpcR)
#AICc(x_fit40)

      # code for a loop to choose a model with lowest AICc:
#for (i in 0:4){for (j in 0:4){ print(i); print(j); print(AICc(arima(x, order = 
#c(i,0,j), method = "ML")))}}


```

## Project
```{r}
# Project description 
The data set I plan to use is the US military expense since 1960. This is money that the US military has used for the defense budget. Although the dataset has two other columns with population of U.S. and GDP, I think the defense budget is more interesting. The GDP and population follow a constant, linear relationship.

# Project motivations and objectives
This data is interesting to me because I have been studying history, especially US history and the wars it has fought or participated in. This data gives me an idea how much the US government spent during the wars and also in the present day. I plan to address the prediction of the defense budget in the next few years (forecasting).
```
There seems to be a trend that is positive but there is no seasonality and no apparent sharp change in behavior.


## reading in data
```{r}
# reading in dataset
spending_data <- read.csv("/Users/josephchang/Desktop/MilitarySpending.csv.xls")
spending_data
plot.ts(spending_data$Year, spending_data$DefenseBudget)
plot(spending_data$Year, spending_data$DefenseBudget, ylab = "Defense budget (in US billion)", xlab = "year", type="l")
```


# transformation, differencing
```{r}
# this is where transformation or difference

# boxcox
t = 1:length(spending_data$DefenseBudget)
fit = lm(spending_data$DefenseBudget~t)
bcTransform = boxcox(spending_data$DefenseBudget ~ t, plotit=TRUE)

# difference once
dat <- diff(spending_data$DefenseBudget, 1)
dat

# twice differenced
dat.2 <- diff(dat, 1)
dat.2
plot.ts(dat.2, type= "l")

# three times differenced
dat.3 <- diff(dat.2,1)
dat.3
plot(dat.3, type= "l")

# check variance
var(spending_data$DefenseBudget)
var(dat)
var(dat.2)
var(dat.3)
```
I differenced the data and found out d=2. I used variance to check and found its lowest variance when d=2.

## plot ACF and PACF
```{r}
# this is where I plot ACF and PACF
acf(spending_data$DefenseBudget, lag.max=100)
pacf(spending_data$DefenseBudget, lag.max=100)

acf(dat, lag.max = 100)
pacf(dat, lag.max=100)

acf(dat.2, lag.max=100, main="Sample acf", ylim=c(-1,1),xlab="h", ylab= expression(hat(rho)[X](h)))
pacf(dat.2, lag.max=100, main="Sample pacf", ylim=c(-1,1),xlab="h", ylab= expression(hat(rho)[X](h)))
```

There are some candidates for this model. One is ARMA(9,9). Since ACF and PACF both show lag 9 outside the confidence interval, one could assume this to be ARMA(9,9). Another candidate could be SARIMA(0,2,0)(1,0,1)_9. Since I found difference to be 2, d=2, P = Q = 1, and seasonality at 9. 

