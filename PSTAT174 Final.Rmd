---
title: "PSTAT174 Project"
author: "Joseph Chang"
date: "3/11/2022"
output: pdf_document
---

```{r setup, include=FALSE}
#install.packages(c('tidyverse', 'knitr'))
knitr::opts_chunk$set(echo = TRUE)
library(knitr)
library(tidyverse) 
library(ISLR) 
library(ROCR)
library(dplyr)
library(tinytex)
library(MASS)
devtools::install_github("FinYang/tsdl")
library(tsdl)
library(forecast)
library(astsa)
```

# Project description 
The data set I plan to use is the US military expense since 1960. This is money that the US military has used for the defense budget. Although the dataset has two other columns with population of U.S. and GDP, I think the defense budget is more interesting. The GDP and population follow a constant, linear relationship.

# Project motivations and objectives
This data is interesting to me because I have been studying history, especially US history and the wars it has fought or participated in. This data gives me an idea how much the US government spent during the wars and also in the present day. I plan to address the prediction of the defense budget in the next few years (forecasting).

There seems to be a trend that is positive but there is no seasonality and no apparent sharp change in behavior.

## Data Import
```{r}
# reading in dataset
spending_data <- read.csv("/Users/josephchang/Desktop/MilitarySpending.csv.xls")

plot.ts(spending_data$Year, spending_data$DefenseBudget, ylab = "Defense budget (in US billion)", xlab = "Year", type="l")

plot(spending_data$Year, spending_data$DefenseBudget, ylab = "Defense budget (in US billion)", xlab = "Year", type="l")
```

# transformation
```{r}
# boxcox transformation
t = 1:length(spending_data$DefenseBudget)
fit = lm(spending_data$DefenseBudget~t)
bcTransform = boxcox(spending_data$DefenseBudget ~ t, plotit=TRUE)

lambda = bcTransform$x[which(bcTransform$y == max(bcTransform$y))]
spent = (1/lambda)*(spending_data$DefenseBudget^lambda-1)

spending_data.log = log(spending_data$DefenseBudget)
plot.ts(spending_data.log)

spending_data.sqrt = log(spending_data$DefenseBudget)
plot.ts(spending_data.sqrt)

# compare transforms
op=par(mfrow=c(2,2))
ts.plot(spending_data$DefenseBudget, main = "Original Time Series")
ts.plot(spent, main = "Box-cox Transform")
ts.plot(spending_data.log, main = "Log transform")
ts.plot(spending_data.sqrt, main = "Square root transform")

# histogram of spent vs original
hist(spent)
hist(spending_data$DefenseBudget)
# spent seems more normal while original is skewed

# time series plot of spent vs original
plot.ts(spent)
plot.ts(spending_data$DefenseBudget)
# both plots look around the same, but spent seems to have more spent in the median


# Based from the histogram, I will use the spent instead of the original data 
```

## Differencing
```{r}
# difference once
dat <- diff(spent, 1)
dat
plot.ts(dat, type= "l")

# twice differenced
dat.2 <- diff(dat, 1)
dat.2
plot.ts(dat.2, type= "l")

# three times differenced
dat.3 <- diff(dat.2,1)
dat.3
plot(dat.3, type= "l")

# check variance
var(spent)
var(dat)
var(dat.2)
var(dat.3)

# I differenced the data and found d to be 2. Based from the variance, the lowest variance is when d=2. At d =3, variance is increased again, therefore I will take d=2.
```


## plot ACF and PACF: Model Identification
```{r}
# ACF, PACF for spent
opar <- par(no.readonly = T)
par(mfrow=c(2,1))
acf(spent, lag.max=100)
pacf(spent, lag.max=100)
par(opar)

# ACF, PACF for dat (difference once)
opar <- par(no.readonly = T)
par(mfrow=c(2,1))
acf(dat, lag.max = 100)
pacf(dat, lag.max=100)

# ACF, PACF for dat.2 (difference twice)
opar <- par(no.readonly = T)
par(mfrow=c(2,1))
acf(dat.2, lag.max=100, main="Sample acf", ylim=c(-1,1),xlab="h", ylab= expression(hat(rho)[X](h)))
pacf(dat.2, lag.max=100, main="Sample pacf", ylim=c(-1,1),xlab="h", ylab= expression(hat(rho)[X](h)))

# Based from the ACF, PACF graphs, one candidate for this model is ARMA(9,9). Since ACF and PACF both show lag 9 outside the confidence interval, one could assume this to be ARMA(9,9). Another candidate could be SARIMA(0,2,0)(1,0,1)_9. Since I found difference to be 2, d=2, P = Q = 1, and seasonality at 9. 
```

## Select models to fit: Model estimation
```{r}
# Model 1 : SARIMA(0, 2, 0)(1, 0, 1) 9
fit.1 <- sarima(xdata = spent, details = F, p=0, d=2, q=0, P=1, D=0, Q=1, S=9 )
cat("Coefficients")
fit.1$fit$coef

# variance of white noise
cat("Variance of White Noise")
fit.1$fit$sigma2


# Model 2 : ARMA(9,9)
fit.2 <- sarima(xdata = spent, details = F, no.constant = T, p=0, d=2, q=0, P=1, D=0, Q=1, S=9 )
cat("Coefficients")
fit.1$fit$coef
  
# variance of white noise
cat("Variance of White Noise")
fit.2$fit$sigma2

# One candidate could be (1+0.457 B^9)Yt = (1-0.1825 B^9) Zt 
# (1 + 0.457 B^9)(1-B^9)(1-B)Xt = (1-0.1825 B^9) Zt where Zt ~ WN(0, 0.0625159)


# MA(9)
source("innovations.r")
acvf = acf(spent, plot=FALSE, lag.max= length(spent))$acf[,1,1]* var(spent)
m = length(acvf)
lh.ia = innovations.algorithm(m+1, acvf)
lh.ia$thetas[9, 1:9]
```


## 
```{r}

```


fit model, (for loop) using aICC, find 2 best models, do diagnostics ( boxtest,), bestmodel passes, forecasting
```{r}

```


## Glossary
```{r, eval=FALSE}
# defines working directory
getwd()
setwd("/Users/josephchang/Desktop")

# reads data and plots data
read.csv("/Users/josephchang/Desktop/MilitarySpending.csv.xls")
plot.ts(spend$Year, spend$DefenseBudget)

# simulate and plot ARMA models
plot.ts(arima.sim(model=list(ar=c(0.8), ma=c(0.3)), n = 100, sd = 1), main="ARMA(1,1), ar
c=0.8, ma c=0.3")

plot(0:100,ARMAacf(ar=c(0.8), ma=c(0.3), lag.max=100),xlim=c(1,40),ylab="r",type="h",
main="ACF for ARMA(1,1) ar c=0.8, ma c=0.3") ; abline(h=0)
    
# add trend and mean line to the original time series plot
#abline()
#abline(h=mean(), col='pink')

# calculate and plot theoretical acf/pacf for ARMA models
plot(ARMAacf(ar=c(-0.95), lag.max=40), col = 'blue', type='h', xlab='lag', ylim=c(-0.8,1))
abline(h=0)
plot(ARMAacf(ar=c(-0.95), lag.max=40, pacf=TRUE), type='h', xlab='lag', ylim=c(-0.8,1))
abline(h=0)

# calculate and plot sample acf/pacf;
ar2 <- arima.sim(model=list(ar=c(0.8, -0.12), sd=1), n=200)
acf(ar2, lag.max=20, main="Sample acf", ylim=c(-1,1),xlab="h", ylab= expression(hat(rho)[X](h)))
pacf(ar2, lag.max=20, main="Sample pacf", ylim=c(-1,1),xlab="h", ylab= expression(hat(rho)[X](h)))

# check whether a particular model is causal/invertible (R commands to find and plot roots of polynomials)
polyroot(c(1, -1.3, 0.7))
#source("plot.roots.R")
#plot.roots(NULL,polyroot(c(1, -1.35, 0.77)), main="roots of ar part")
#plot.roots(NULL,polyroot(c(1,0.64)), main="roots of ma part")
#plot.roots(NULL,polyroot(c(1, -2, 2.02, -1.07, 0.34)), main="roots of ar part") 

install.packages("UnitCircle")
library(UnitCircle)
uc.check(pol_ = c(1, -1.35,0.77), plot_output = TRUE)

# perform Box-Cox transforms;
library(MASS)
#t = 1:length(wine)
#fit = lm(wine~t)
#bcTransform = boxcox(wine ~ t, plotit=TRUE)

# perform differencing data at lags 1 and 12;
#uspopdiff1 <- diff(uspop)
#plot.ts(uspopdiff1)
#abline(lm(uspopdiff1 ~ as.numeric(1:length(uspopdiff1))
          
#AP=read.table("pass.txt")
#plot.ts(AP)
#APdiff12 <- diff(AP, lag=12, differences = 1)
#plot.ts(APdiff12)
#abline(lm(APdiff12 ~ as.numeric(1:length(APdiff12))) )
          
# perform Yule-Walker estimation and find standard deviations of the estimates.
#ar(x, aic=TRUE, order.max=NULL, method=c('yule-walker'))
#x.ywest$ar

# perform MLE and check AICC associated with the model.
#x_fit40 = arima(x, order = c(4,0,0), method = "ML")
#library(qpcR)
#AICc(x_fit40)

      # code for a loop to choose a model with lowest AICc:
#for (i in 0:4){for (j in 0:4){ print(i); print(j); print(AICc(arima(x, order = 
#c(i,0,j), method = "ML")))}}
```

